{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Document Classification\n",
    "\n",
    "### Alice Ding, Shoshana Farber, Christian Uriostegui\n",
    "\n",
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  \n",
    "\n",
    "For this project, we've chosen to use two files from [spamasssassin](https://spamassassin.apache.org/old/publiccorpus/) as our training data. This is a list of 2,551 ham (non-spam) emails and 1,398 spam ones to see whether the document is spam or not.\n",
    "\n",
    "### Importing the Data\n",
    "\n",
    "To start, we have the files downloaded in two different folders within this directory; we'll be using Python to read each file and put it into one full dataframe with messages and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From exmh-workers-admin@redhat.com  Thu Aug 22...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From Steve_Burt@cursor-system.com  Thu Aug 22 ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From timc@2ubh.com  Thu Aug 22 13:52:59 2002\\n...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From irregulars-admin@tb.tf  Thu Aug 22 14:23:...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From exmh-users-admin@redhat.com  Thu Aug 22 1...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email label\n",
       "0  From exmh-workers-admin@redhat.com  Thu Aug 22...   ham\n",
       "1  From Steve_Burt@cursor-system.com  Thu Aug 22 ...   ham\n",
       "2  From timc@2ubh.com  Thu Aug 22 13:52:59 2002\\n...   ham\n",
       "3  From irregulars-admin@tb.tf  Thu Aug 22 14:23:...   ham\n",
       "4  From exmh-users-admin@redhat.com  Thu Aug 22 1...   ham"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from os.path import expanduser\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# get the path names of each directory\n",
    "ham = sys.path[0] + '/easy_ham'\n",
    "spam = sys.path[0] + '/spam'\n",
    "\n",
    "# create a function that takes the directory and the label we want appended to those messages to put into a dataframe\n",
    "def create_df(folder, label):\n",
    "    file_data = []\n",
    "    file_labels = []\n",
    "    for file_name in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, 'r', encoding='latin-1') as file:\n",
    "                content = file.read()\n",
    "        file_data.append(content)\n",
    "        file_labels.append(label)\n",
    "    df = pd.DataFrame({'email': file_data, 'label': file_labels})\n",
    "    return df\n",
    "\n",
    "# create a dataframe for the ham messages\n",
    "ham_df = create_df(ham, 'ham')\n",
    "# create a dataframe for the spam messages\n",
    "spam_df = create_df(spam, 'spam')\n",
    "# combine these dataframes into one full one of emails\n",
    "full_df = pd.concat([ham_df, spam_df])\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is imported, let's try to clean it up to only hold relevant information.\n",
    "\n",
    "### Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>exmhworkersadminredhatcom thu aug returnpath d...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>steve_burtcursorsystemcom thu aug returnpath d...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>timcubhcom thu aug returnpath deliveredto zzzz...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>irregularsadmintbtf thu aug returnpath deliver...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exmhusersadminredhatcom thu aug returnpath del...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email label\n",
       "0  exmhworkersadminredhatcom thu aug returnpath d...   ham\n",
       "1  steve_burtcursorsystemcom thu aug returnpath d...   ham\n",
       "2  timcubhcom thu aug returnpath deliveredto zzzz...   ham\n",
       "3  irregularsadmintbtf thu aug returnpath deliver...   ham\n",
       "4  exmhusersadminredhatcom thu aug returnpath del...   ham"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get stop words from nltk\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# create a function to clean a given text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)              # remove HTML tags\n",
    "    text = re.sub(r\"[0-9]\", \"\", text)               # remove digits\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)             # remove non-word and non-space characters\n",
    "    text = re.sub(r\"\\n\", \"\", text)                  # remove newlines\n",
    "    text = text.lower()                            # convert all text to lowercase\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])  # remove stop words\n",
    "    text = nltk.PorterStemmer().stem(text) # gets stem root for words\n",
    "    return text\n",
    "\n",
    "full_df['email'] = full_df['email'].apply(clean_text)\n",
    "\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things are definitely looking cleaner! Now we're going to transform to further transform the dataset to allow for smoother analysis. There is also the addition of the ham and spam classification, where 0 indicates that it is non-spam and 1 indicates the email is spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed text data\n",
    "X = vectorizer.fit_transform(full_df[\"email\"])\n",
    "\n",
    "# Extract the labels\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the document-term matrix to a dataframe\n",
    "full_df_matrix = pd.DataFrame(X.toarray(), columns=terms)\n",
    "\n",
    "# Add the spam ham classification\n",
    "full_df_matrix[\"class\"] = full_df[\"label\"].map({\"ham\": 0, \"spam\": 1}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is in the proper format, we can now create our model. The model will be split between 70% training data and 30% testing data . We're also going to try the Random Forest Classifier with 300 trees.\n",
    "\n",
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[776   0]\n",
      " [  2 138]]\n",
      "Accuracy: 0.9978165938864629\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(full_df_matrix.drop(\"class\", axis=1), full_df_matrix[\"class\"], test_size=0.3, random_state=1234)\n",
    "\n",
    "# Create a Random Forest classifier with 300 trees\n",
    "classifier = RandomForestClassifier(n_estimators=300)\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "confusion = confusion_matrix(y_test, predicted)\n",
    "print(confusion)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model generated a 99.78% accuracy - pretty good! Looking at the confusion matrix, it tells us that there are 776 true negatives. These are the instances that the classifier correctly identified \"ham\" emails. It also tells us that there are 138 true positives - which is when the classifier correctly identified \"spam\" emails.\n",
    "\n",
    "Our model did not classify \"ham\" email as \"spam\" (0), however we can see that the model did incorrectly label 2 spam \"emails\" as \"ham\".\n",
    "\n",
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using Random Forest, the model was pretty successful; a next step would be to use various other models (Naive Bayes as an example) to compare and see which is most efficient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8938740c0a294b0bb463709b29f839994c0cf0da429cfc65f1491f488a740231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
