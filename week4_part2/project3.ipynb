{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3\n",
    "\n",
    "### Alice Ding, Shoshana Farber, Christian Uriostegui\n",
    "\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. How does the performance on the test set compare to the performance on the dev-test set? Is this what you'd expect?\n",
    "\n",
    "For this project, we'll be using Supervised Classification in order to build a name gender classifier. According to the book, \"a classifier is called *supervised* if it is built on training corpora containing the correct label for each input.\" Using this framework, we will do our best to take a list of names, split it into training and testing data, and then use the training data to build a model and then classify the testing data accordingly.\n",
    "\n",
    "We'll be taking a lot of inspiration from the book in order to this analysis.\n",
    "\n",
    "### Importing Packages and the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.classify import apply_features\n",
    "import pandas as pd\n",
    "\n",
    "# grab all of the names\n",
    "from nltk.corpus import names\n",
    "names = ([(name, 'male') for name in names.words ('male.txt')] +\n",
    "        [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "# use the random package to shuffle the names\n",
    "import random\n",
    "rng = random.Random()\n",
    "rng.seed(1358)\n",
    "rng.shuffle(names)\n",
    "\n",
    "# create the subsets of names\n",
    "train_names = names[1000:]\n",
    "devtest_names = names[500:1000]\n",
    "test_names = names[:500]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Identification\n",
    "\n",
    "#### Last Letter\n",
    "\n",
    "Female and male names have distinctive characteristics: names ending in a, e, and i are likely to be female while names ending in s, r, o, and k are likely to be male. Taking this code from chapter 6 of Natural Language Processing with Python, we can build a dictionary containing that relevant information after given a name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'last_letter': 'k'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}\n",
    "gender_features('Shrek')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use this function on our names dataset and then split our data into a training and testing set. We'll then use Naive Bayes to classify the datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using apply_features to avoid using a large amount of memory\n",
    "train_set = apply_features(gender_features, train_names)\n",
    "test_set = apply_features(gender_features, test_names)\n",
    "devtest_set = apply_features(gender_features, devtest_names)\n",
    "classifier1 = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we try using this classifier on a few names that aren't in either dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tyrion: male\n",
      "Cersei: female\n"
     ]
    }
   ],
   "source": [
    "print('Tyrion:', classifier1.classify(gender_features('Tyrion')))\n",
    "print('Cersei:', classifier1.classify(gender_features('Cersei')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these Game of Thrones characters, this seemed to work well.\n",
    "\n",
    "How does the accuracy of our model look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.752"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier1, test_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "75.2%, not too bad. What does the classifer say about what features it found most effective for classifying each name's gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     43.1 : 1.0\n",
      "             last_letter = 'k'              male : female =     29.9 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.3 : 1.0\n",
      "             last_letter = 'd'              male : female =     10.6 : 1.0\n",
      "             last_letter = 'm'              male : female =      9.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier1.show_most_informative_features(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, this is telling us that:\n",
    "\n",
    "- Names that end with a are 43.1 times more likely to be female\n",
    "- Names that end with k are 29.9 times more likely to be male\n",
    "- Names that end with f are 15.3 times more likely to be male\n",
    "- Names that end with d are 10.6 times more likely to be male\n",
    "- Names that end with m are 9.0 times more likely to be male\n",
    "\n",
    "What other features can we add to this model to make it a little better?\n",
    "\n",
    "#### Adding First Letter and Count of All Letters\n",
    "\n",
    "Let's make a new function that finds the last letter, first letter, and a count of all letters used in the name, then use this to train a new model and determine its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.756\n"
     ]
    }
   ],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"lastletter\"] = name[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    return features\n",
    "\n",
    "# using apply_features to avoid using a large amount of memory\n",
    "train_set = apply_features(gender_features2, train_names)\n",
    "test_set = apply_features(gender_features2, test_names)\n",
    "devtest_set = apply_features(gender_features2, devtest_names)\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier2, test_set))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 75.6%, this is higher than our previous 75.2%!\n",
    "\n",
    "The next thing we can do is start refining the feature set for error analysis; let's look at the accuracy of our devtest set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier2, devtest_set))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a 75% accuracy, let's see what some of the errors were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>guess</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Abdel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Abelard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Addie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Allah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Amadeus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Ambrose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Anatole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Andie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Antin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Armando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Bailie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Bart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Barth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Bartolomeo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Bennie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Boniface</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Brice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Brodie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Bryant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Bubba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual   guess        name\n",
       "0    male  female       Abdel\n",
       "1    male  female     Abelard\n",
       "2    male  female       Addie\n",
       "3    male  female       Allah\n",
       "4    male  female     Amadeus\n",
       "5    male  female     Ambrose\n",
       "6    male  female     Anatole\n",
       "7    male  female       Andie\n",
       "8    male  female       Antin\n",
       "9    male  female     Armando\n",
       "10   male  female      Bailie\n",
       "11   male  female        Bart\n",
       "12   male  female       Barth\n",
       "13   male  female  Bartolomeo\n",
       "14   male  female      Bennie\n",
       "15   male  female    Boniface\n",
       "16   male  female       Brice\n",
       "17   male  female      Brodie\n",
       "18   male  female      Bryant\n",
       "19   male  female       Bubba"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = []\n",
    "# for each name and its given tag\n",
    "for (name, tag) in devtest_names:\n",
    "    # get the classifier's guess\n",
    "    guess = classifier2.classify(gender_features(name))\n",
    "    # if the guess does not match the correct classification\n",
    "    if guess != tag:\n",
    "        # add it to the list of errors\n",
    "        errors.append( (tag, guess, name))\n",
    "\n",
    "errors = pd.DataFrame(sorted(errors), columns = ['actual', 'guess', 'name'])\n",
    "\n",
    "errors.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list above, it looks like combinations of characters for the suffixes can be more indicative of gender than just the one letter. For example, names that end with `yn` are likely to be female while names that end with just `n` are typically male. To adjust for this, let's add a feature that takes the last two letters of a person's name as well. Perhaps it'd even be helpful to add in bigrams (pairs of consecutive letters).\n",
    "\n",
    "#### Adding Combinations of Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8355414746543779\n"
     ]
    }
   ],
   "source": [
    "def gender_features3(name):\n",
    "    features = {}\n",
    "    i = 0\n",
    "    features[\"firstletter\"] = name[0].lower()\n",
    "    features[\"suffix1\"] = name[-1].lower()\n",
    "    features[\"suffix2\"] = name[-2].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.lower().count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name.lower())\n",
    "    for w in nltk.bigrams(name):\n",
    "        features[('b'+str(i))] = (w[0] + w[1]).lower()\n",
    "        i = i+1\n",
    "    return features\n",
    "\n",
    "# using apply_features to avoid using a large amount of memory\n",
    "train_set = apply_features(gender_features3, train_names)\n",
    "devtest_set = apply_features(gender_features3, devtest_names)\n",
    "test_set = apply_features(gender_features3, train_names)\n",
    "classifier3 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier3, test_set))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now at 83.6% accuracy -- this is the highest we've seen! \n",
    "\n",
    "What are some of the most informative features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 suffix1 = 'a'            female : male   =     43.1 : 1.0\n",
      "                 suffix1 = 'k'              male : female =     29.9 : 1.0\n",
      "                      b5 = 'ta'           female : male   =     20.9 : 1.0\n",
      "                      b5 = 'na'           female : male   =     16.6 : 1.0\n",
      "                 suffix1 = 'f'              male : female =     15.3 : 1.0\n",
      "                      b6 = 'rd'             male : female =     15.2 : 1.0\n",
      "                      b4 = 'us'             male : female =     13.9 : 1.0\n",
      "                      b3 = 'to'             male : female =     13.5 : 1.0\n",
      "                      b2 = 'sa'           female : male   =     13.5 : 1.0\n",
      "                      b5 = 'rd'             male : female =     12.9 : 1.0\n",
      "                      b4 = 'na'           female : male   =     12.6 : 1.0\n",
      "                      b5 = 'ra'           female : male   =     12.1 : 1.0\n",
      "                      b2 = 'rk'             male : female =     11.6 : 1.0\n",
      "                      b2 = 'ta'           female : male   =     11.1 : 1.0\n",
      "                      b4 = 'ss'           female : male   =     11.0 : 1.0\n",
      "                 suffix1 = 'd'              male : female =     10.6 : 1.0\n",
      "                      b3 = 'co'             male : female =     10.5 : 1.0\n",
      "                      b3 = 'mu'             male : female =     10.5 : 1.0\n",
      "                      b5 = 'rt'             male : female =     10.4 : 1.0\n",
      "                      b2 = 'ly'           female : male   =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier3.show_most_informative_features(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suffices and bigrams seem to be the most informative here -- very interesting!\n",
    "\n",
    "Let's go over the overall performance of the three models we created here.\n",
    "\n",
    "#### Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Last Letter Classifier check:                                                0.6304723502304147\n",
      "Accuracy with First and Last Letter with Letter Counts Classifer check:                    0.7111175115207373\n",
      "Accuracy with First and Last Letter with Letter Counts Classifer and Bigrams check:        0.8355414746543779\n"
     ]
    }
   ],
   "source": [
    "classifier1_accuracy = nltk.classify.accuracy(classifier1, test_set)\n",
    "classifier2_accuracy = nltk.classify.accuracy(classifier2, test_set)\n",
    "classifier3_accuracy = nltk.classify.accuracy(classifier3, test_set)\n",
    "\n",
    "print(\"Accuracy with Last Letter Classifier check:                                                {}\".format(classifier1_accuracy))\n",
    "print(\"Accuracy with First and Last Letter with Letter Counts Classifer check:                    {}\".format(classifier2_accuracy))\n",
    "print(\"Accuracy with First and Last Letter with Letter Counts Classifer and Bigrams check:        {}\".format(classifier3_accuracy))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solely based on these training and testing datasets, it seems like the last model does much better at predicting gender based on names."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8938740c0a294b0bb463709b29f839994c0cf0da429cfc65f1491f488a740231"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
